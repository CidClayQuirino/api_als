{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyQD9Bdnj7Wa5ltLPm54pT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CidClayQuirino/api_als/blob/main/api_als.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Optional, Dict, Any, List\n",
        "\n",
        "# ============================================\n",
        "# CONFIGURAÇÕES DA API\n",
        "# ============================================\n",
        "\n",
        "LOGIN_URL = \"https://integration.s360web.com/api/login\"\n",
        "API_BASE = \"https://integration.s360web.com/api/v1\"\n",
        "\n",
        "# Use variáveis de ambiente se preferir não hardcodar credenciais\n",
        "USER = os.getenv(\"S360_USER\", \"integracao.komatsu\")\n",
        "PASSWORD = os.getenv(\"S360_PASSWORD\", \"o8sqfl5h\")\n",
        "\n",
        "# Pasta local onde os CSV serão salvos (Ex.: Google Colab usa /content/)\n",
        "PASTA_SAIDA = \"/content/s360_export/\"\n",
        "\n",
        "# Período de coleta: últimos N dias (1 ano = 365)\n",
        "PERIODO_DIAS = 365\n",
        "\n",
        "# Timeout (conexão, leitura) e tentativas\n",
        "TIMEOUT = (10, 60)     # (connect, read) em segundos\n",
        "MAX_RETRIES = 3\n",
        "RETRY_BACKOFF = 2      # base para backoff exponencial: 2, 4, 8...\n",
        "\n",
        "# Rate limit entre chamadas (se necessário pela API)\n",
        "RATE_LIMIT_SLEEP = 2   # segundos\n",
        "\n",
        "# Configuração de CSV (mantenha ',' se preferir padrão internacional)\n",
        "CSV_SEPARADOR = \",\"    # em pt-BR, alguns preferem ';'\n",
        "CSV_ENCODING = \"utf-8-sig\"  # BOM para Excel (Windows)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# UTILITÁRIOS\n",
        "# ============================================\n",
        "\n",
        "def log_resp(r: requests.Response, prefix: str = \"\") -> None:\n",
        "    \"\"\"Loga informações úteis da resposta HTTP para diagnóstico.\"\"\"\n",
        "    ct = r.headers.get(\"Content-Type\", \"\")\n",
        "    print(f\"{prefix}Status: {r.status_code} {r.reason} | Content-Type: {ct}\")\n",
        "    body = r.text or \"\"\n",
        "    print(f\"{prefix}Body (até 1000 chars): {body[:1000]}\")\n",
        "    # Cabeçalhos comumente relevantes\n",
        "    importantes = ['date', 'server', 'x-request-id', 'x-correlation-id']\n",
        "    print(f\"{prefix}Headers: { {k: v for k, v in r.headers.items() if k.lower() in importantes} }\")\n",
        "\n",
        "\n",
        "def ensure_dir(path: str) -> None:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# AUTENTICAÇÃO\n",
        "# ============================================\n",
        "\n",
        "def autenticar(session: Optional[requests.Session] = None) -> str:\n",
        "    \"\"\"\n",
        "    Autentica e retorna o token. Faz retries para status transitórios (429/5xx)\n",
        "    e detalha qualquer falha. Tenta chaves alternativas no payload se 400/401.\n",
        "    \"\"\"\n",
        "    sess = session or requests.Session()\n",
        "\n",
        "    payload = {\"login\": USER, \"password\": PASSWORD}\n",
        "    alt_payloads = [\n",
        "        {\"username\": USER, \"password\": PASSWORD},\n",
        "        {\"user\": USER, \"password\": PASSWORD},\n",
        "        {\"email\": USER, \"password\": PASSWORD},\n",
        "    ]\n",
        "\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            r = sess.post(LOGIN_URL, json=payload, timeout=TIMEOUT)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"[LOGIN] Falha de rede na tentativa {attempt}/{MAX_RETRIES}: {e}\")\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            try:\n",
        "                data = r.json()\n",
        "            except ValueError:\n",
        "                log_resp(r, prefix=\"[LOGIN] \")\n",
        "                raise RuntimeError(\"[LOGIN] Resposta não-JSON, impossível obter token.\")\n",
        "\n",
        "            token = data.get(\"token\") or data.get(\"access_token\") or data.get(\"accessToken\") or data.get(\"jwt\")\n",
        "            if not token:\n",
        "                print(\"[LOGIN] Token não encontrado nas chaves conhecidas. Chaves recebidas:\", list(data.keys()))\n",
        "                log_resp(r, prefix=\"[LOGIN] \")\n",
        "                raise RuntimeError(\"[LOGIN] Token ausente na resposta.\")\n",
        "            return token\n",
        "\n",
        "        log_resp(r, prefix=f\"[LOGIN] Tentativa {attempt}/{MAX_RETRIES} \")\n",
        "        if r.status_code in (429, 500, 502, 503, 504):\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        if r.status_code in (400, 401) and attempt == 1:\n",
        "            print(\"[LOGIN] Tentando variações de payload (username/email)...\")\n",
        "            for alt in alt_payloads:\n",
        "                try:\n",
        "                    r2 = sess.post(LOGIN_URL, json=alt, timeout=TIMEOUT)\n",
        "                except requests.exceptions.RequestException as e:\n",
        "                    print(f\"[LOGIN] Falha de rede com payload alternativo: {e}\")\n",
        "                    continue\n",
        "                if r2.status_code == 200:\n",
        "                    try:\n",
        "                        data2 = r2.json()\n",
        "                    except ValueError:\n",
        "                        log_resp(r2, prefix=\"[LOGIN/ALT] \")\n",
        "                        raise RuntimeError(\"[LOGIN/ALT] Resposta não-JSON.\")\n",
        "                    token = data2.get(\"token\") or data2.get(\"access_token\") or data2.get(\"accessToken\") or data2.get(\"jwt\")\n",
        "                    if token:\n",
        "                        print(\"[LOGIN] Autenticado com payload alternativo:\", alt.keys())\n",
        "                        return token\n",
        "                    else:\n",
        "                        log_resp(r2, prefix=\"[LOGIN/ALT] \")\n",
        "                        raise RuntimeError(\"[LOGIN/ALT] Token ausente.\")\n",
        "                else:\n",
        "                    log_resp(r2, prefix=\"[LOGIN/ALT] \")\n",
        "\n",
        "        raise RuntimeError(f\"[LOGIN] Erro ao autenticar. Status={r.status_code}. Veja logs acima.\")\n",
        "\n",
        "    raise RuntimeError(\"[LOGIN] Não foi possível autenticar após múltiplas tentativas.\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# CHAMADA GENÉRICA DE API COM RETRY\n",
        "# ============================================\n",
        "\n",
        "def chamar_api(method: str, endpoint: str, token: str,\n",
        "               params: Optional[Dict[str, Any]] = None,\n",
        "               body: Optional[Dict[str, Any]] = None,\n",
        "               session: Optional[requests.Session] = None) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Faz chamada GET/POST com token, timeout, retry para erros transitórios,\n",
        "    e logs detalhados de falha.\n",
        "    \"\"\"\n",
        "    sess = session or requests.Session()\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "    url = f\"{API_BASE.rstrip('/')}/{endpoint.lstrip('/')}\"\n",
        "\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            if method.upper() == \"GET\":\n",
        "                r = sess.get(url, headers=headers, params=params, timeout=TIMEOUT)\n",
        "            else:\n",
        "                r = sess.post(url, headers=headers, json=body, timeout=TIMEOUT)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"[API] Falha de rede em {method} {url} (tentativa {attempt}/{MAX_RETRIES}): {e}\")\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            try:\n",
        "                data = r.json()\n",
        "            except ValueError:\n",
        "                log_resp(r, prefix=\"[API] \")\n",
        "                print(\"[API] Resposta não-JSON; retornando None.\")\n",
        "                return None\n",
        "            time.sleep(RATE_LIMIT_SLEEP)\n",
        "            return data\n",
        "\n",
        "        log_resp(r, prefix=f\"[API] {method} {endpoint} tentativa {attempt}/{MAX_RETRIES} \")\n",
        "\n",
        "        if r.status_code in (429, 500, 502, 503, 504):\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    print(f\"[API] Desistindo de {method} {endpoint} após {MAX_RETRIES} tentativas.\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# COLETA DE EQUIPAMENTOS\n",
        "# ============================================\n",
        "\n",
        "def coletar_equipamentos(token: str, session: Optional[requests.Session] = None) -> Optional[List[Dict[str, Any]]]:\n",
        "    \"\"\"\n",
        "    Retorna lista de equipamentos ativos. Se a API devolver objeto, tenta extrair 'items'.\n",
        "    \"\"\"\n",
        "    params = {\"ativo\": \"true\"}\n",
        "    dados = chamar_api(\"GET\", \"equipamento/list\", token, params=params, session=session)\n",
        "    if not dados:\n",
        "        return None\n",
        "\n",
        "    if isinstance(dados, list):\n",
        "        return dados\n",
        "\n",
        "    if isinstance(dados, dict) and \"items\" in dados:\n",
        "        return dados[\"items\"]\n",
        "\n",
        "    return [dados]\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# COLETA DE AMOSTRAS (sampleResult/search) COM PERÍODO E PAGINAÇÃO\n",
        "# ============================================\n",
        "\n",
        "def coletar_amostras(token: str, session: Optional[requests.Session] = None) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Coleta amostras dos últimos PERIODO_DIAS até a data atual, varrendo todas as páginas.\n",
        "    Retorna uma lista consolidada de itens.\n",
        "    \"\"\"\n",
        "    data_fim = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    data_inicio = (datetime.now() - timedelta(days=PERIODO_DIAS)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    print(f\"[Amostras] Coletando dados de {data_inicio} até {data_fim}\")\n",
        "\n",
        "    page = 1\n",
        "    page_size = 500\n",
        "    todos_itens: List[Dict[str, Any]] = []\n",
        "\n",
        "    while True:\n",
        "        body = {\n",
        "            \"readingStatus\": None,   # busca tudo\n",
        "            \"markRead\": True,        # marcar como lido\n",
        "            \"startDate\": data_inicio,\n",
        "            \"endDate\": data_fim,\n",
        "            \"page\": page,\n",
        "            \"pageSize\": page_size\n",
        "        }\n",
        "\n",
        "        dados = chamar_api(\"POST\", \"sampleResult/search\", token, body=body, session=session)\n",
        "        if not dados:\n",
        "            # Sem dados ou erro não transitório\n",
        "            break\n",
        "\n",
        "        # Normalmente a API retorna {items: [...], total: X, page: Y}\n",
        "        if isinstance(dados, dict) and isinstance(dados.get(\"items\"), list):\n",
        "            itens = dados[\"items\"]\n",
        "        elif isinstance(dados, list):\n",
        "            itens = dados\n",
        "        else:\n",
        "            itens = [dados]\n",
        "\n",
        "        todos_itens.extend(itens)\n",
        "        print(f\"[Amostras] Página {page}: coletados {len(itens)} itens (total acumulado: {len(todos_itens)})\")\n",
        "\n",
        "        # Heurística de término: se retornou menos que page_size, provavelmente acabou\n",
        "        if len(itens) < page_size:\n",
        "            break\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)  # pequena pausa entre páginas\n",
        "\n",
        "    return todos_itens\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# SALVAR CSV\n",
        "# ============================================\n",
        "\n",
        "def salvar_csv(dados: Any, nome: str) -> None:\n",
        "    \"\"\"\n",
        "    Salva lista/dict em CSV com UTF-8 na pasta configurada.\n",
        "    \"\"\"\n",
        "    ensure_dir(PASTA_SAIDA)\n",
        "    caminho = os.path.join(PASTA_SAIDA, nome)\n",
        "\n",
        "    if isinstance(dados, list):\n",
        "        df = pd.DataFrame(dados)\n",
        "    elif isinstance(dados, dict):\n",
        "        df = pd.DataFrame([dados])\n",
        "    else:\n",
        "        raise ValueError(\"Formato de dados não suportado para CSV.\")\n",
        "\n",
        "    # Exporta CSV (excel-friendly)\n",
        "    df.to_csv(caminho, index=False, encoding=CSV_ENCODING, sep=CSV_SEPARADOR)\n",
        "    print(f\"Arquivo salvo: {caminho}\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# EXECUÇÃO PRINCIPAL\n",
        "# ============================================\n",
        "\n",
        "def executar_rotina():\n",
        "    print(\"Iniciando coleta:\", datetime.now())\n",
        "\n",
        "    session = requests.Session()\n",
        "    token = autenticar(session=session)\n",
        "\n",
        "    # Equipamentos\n",
        "    equipamentos = coletar_equipamentos(token, session=session)\n",
        "    if equipamentos:\n",
        "        salvar_csv(equipamentos, f\"equipamentos_{datetime.now().date()}.csv\")\n",
        "    else:\n",
        "        print(\"[Equipamentos] Nenhum dado retornado.\")\n",
        "\n",
        "    # Amostras (todas as páginas dos últimos PERIODO_DIAS)\n",
        "    amostras = coletar_amostras(token, session=session)\n",
        "    if amostras:\n",
        "        salvar_csv(amostras, f\"amostras_{datetime.now().date()}.csv\")\n",
        "    else:\n",
        "        print(\"[Amostras] Nenhum dado retornado.\")\n",
        "\n",
        "    print(\"Finalizado:\", datetime.now())\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# MAIN\n",
        "# ============================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ensure_dir(PASTA_SAIDA)\n",
        "    try:\n",
        "        executar_rotina()\n",
        "    except Exception as e:\n",
        "        print(\"Falha na execução:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6nQV4upN3z8",
        "outputId": "346e6574-3784-4a43-9299-bfd15c3890e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando coleta: 2026-01-13 16:36:45.787751\n",
            "[LOGIN] Tentativa 1/3 Status: 400 Bad Request | Content-Type: \n",
            "[LOGIN] Tentativa 1/3 Body (até 1000 chars): \n",
            "[LOGIN] Tentativa 1/3 Headers: {'Date': 'Tue, 13 Jan 2026 16:36:46 GMT'}\n",
            "[LOGIN] Tentando variações de payload (username/email)...\n",
            "[LOGIN] Autenticado com payload alternativo: dict_keys(['username', 'password'])\n",
            "[API] GET equipamento/list tentativa 1/3 Status: 405 Method Not Allowed | Content-Type: application/xml;charset=UTF-8\n",
            "[API] GET equipamento/list tentativa 1/3 Body (até 1000 chars): <Map><timestamp>1768322207225</timestamp><status>405</status><error>Method Not Allowed</error><path>/api/v1/equipamento/list</path></Map>\n",
            "[API] GET equipamento/list tentativa 1/3 Headers: {'Date': 'Tue, 13 Jan 2026 16:36:46 GMT'}\n",
            "[Equipamentos] Nenhum dado retornado.\n",
            "[Amostras] Coletando dados de 2025-01-13 até 2026-01-13\n",
            "[Amostras] Página 1: coletados 1 itens (total acumulado: 1)\n",
            "Arquivo salvo: /content/s360_export/amostras_2026-01-13.csv\n",
            "Finalizado: 2026-01-13 16:36:52.450205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Optional, Dict, Any, List, Tuple\n",
        "\n",
        "# ============================================\n",
        "# CONFIGURAÇÕES DA API\n",
        "# ============================================\n",
        "\n",
        "LOGIN_URL = \"https://integration.s360web.com/api/login\"\n",
        "API_BASE = \"https://integration.s360web.com/api/v1\"\n",
        "\n",
        "USER = os.getenv(\"S360_USER\", \"integracao.komatsu\")\n",
        "PASSWORD = os.getenv(\"S360_PASSWORD\", \"o8sqfl5h\")\n",
        "\n",
        "PASTA_SAIDA = \"/content/s360_export/\"\n",
        "PERIODO_DIAS = 365         # backfill de 1 ano\n",
        "CHUNK_DIAS = 31            # janelas mensais para cobrir 100%\n",
        "PAGE_SIZE = 500            # tamanhos grandes (ver limite no portal)\n",
        "TIMEOUT = (10, 60)         # (connect, read)\n",
        "MAX_RETRIES = 3\n",
        "RETRY_BACKOFF = 2          # base exponencial\n",
        "SLEEP_ENTRE_CHAMADAS = 25  # orientação S360\n",
        "\n",
        "CSV_SEPARADOR = \",\"\n",
        "CSV_ENCODING = \"utf-8-sig\"\n",
        "\n",
        "# ============================================\n",
        "# UTILITÁRIOS\n",
        "# ============================================\n",
        "\n",
        "def ensure_dir(path: str) -> None:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def log_resp(r: requests.Response, prefix: str = \"\") -> None:\n",
        "    ct = r.headers.get(\"Content-Type\", \"\")\n",
        "    print(f\"{prefix}Status: {r.status_code} {r.reason} | Content-Type: {ct}\")\n",
        "    body = r.text or \"\"\n",
        "    print(f\"{prefix}Body (até 1000 chars): {body[:1000]}\")\n",
        "    importantes = ['date', 'server', 'x-request-id', 'x-correlation-id']\n",
        "    print(f\"{prefix}Headers: { {k: v for k, v in r.headers.items() if k.lower() in importantes} }\")\n",
        "\n",
        "# ============================================\n",
        "# AUTENTICAÇÃO\n",
        "# ============================================\n",
        "\n",
        "def autenticar(session: Optional[requests.Session] = None) -> str:\n",
        "    sess = session or requests.Session()\n",
        "    payloads = [\n",
        "        {\"login\": USER, \"password\": PASSWORD},    # já funciona no seu ambiente\n",
        "        {\"username\": USER, \"password\": PASSWORD}, # variação vista no dev portal\n",
        "        {\"email\": USER, \"password\": PASSWORD},\n",
        "    ]\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        for payload in payloads:\n",
        "            try:\n",
        "                r = sess.post(LOGIN_URL, json=payload, timeout=TIMEOUT)\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"[LOGIN] Falha de rede {attempt}/{MAX_RETRIES}: {e}\")\n",
        "                time.sleep(RETRY_BACKOFF ** attempt)\n",
        "                continue\n",
        "\n",
        "            if r.status_code == 200:\n",
        "                try:\n",
        "                    data = r.json()\n",
        "                except ValueError:\n",
        "                    log_resp(r, prefix=\"[LOGIN] \")\n",
        "                    raise RuntimeError(\"[LOGIN] Resposta não-JSON.\")\n",
        "                token = data.get(\"token\") or data.get(\"access_token\") or data.get(\"accessToken\") or data.get(\"jwt\")\n",
        "                if token:\n",
        "                    print(\"[LOGIN] Autenticado com payload:\", list(payload.keys()))\n",
        "                    return token\n",
        "                log_resp(r, prefix=\"[LOGIN] \")\n",
        "                raise RuntimeError(\"[LOGIN] Token ausente na resposta.\")\n",
        "            else:\n",
        "                log_resp(r, prefix=\"[LOGIN] \")\n",
        "\n",
        "        # 429/5xx: backoff\n",
        "        time.sleep(RETRY_BACKOFF ** attempt)\n",
        "\n",
        "    raise RuntimeError(\"[LOGIN] Não foi possível autenticar após múltiplas tentativas.\")\n",
        "\n",
        "# ============================================\n",
        "# CHAMADAS DE API (GET/POST) COM RETRY\n",
        "# ============================================\n",
        "\n",
        "def chamar_api(method: str, endpoint: str, token: str,\n",
        "               params: Optional[Dict[str, Any]] = None,\n",
        "               body: Optional[Dict[str, Any]] = None,\n",
        "               session: Optional[requests.Session] = None) -> Optional[Dict[str, Any]]:\n",
        "    sess = session or requests.Session()\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "    url = f\"{API_BASE.rstrip('/')}/{endpoint.lstrip('/')}\"\n",
        "\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            if method.upper() == \"GET\":\n",
        "                r = sess.get(url, headers=headers, params=params, timeout=TIMEOUT)\n",
        "            else:\n",
        "                r = sess.post(url, headers=headers, json=body, timeout=TIMEOUT)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"[API] Falha de rede em {method} {url} ({attempt}/{MAX_RETRIES}): {e}\")\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            try:\n",
        "                data = r.json()\n",
        "            except ValueError:\n",
        "                log_resp(r, prefix=\"[API] \")\n",
        "                print(\"[API] Resposta não-JSON; retornando None.\")\n",
        "                return None\n",
        "            # sleep entre chamadas (orientação S360)\n",
        "            time.sleep(SLEEP_ENTRE_CHAMADAS)\n",
        "            return data\n",
        "\n",
        "        log_resp(r, prefix=f\"[API] {method} {endpoint} tentativa {attempt}/{MAX_RETRIES} \")\n",
        "        if r.status_code in (429, 500, 502, 503, 504):\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    print(f\"[API] Desistindo de {method} {endpoint} após {MAX_RETRIES} tentativas.\")\n",
        "    return None\n",
        "\n",
        "# ============================================\n",
        "# EQUIPAMENTOS (ativos)\n",
        "# ============================================\n",
        "\n",
        "def coletar_equipamentos(token: str, session: Optional[requests.Session] = None) -> Optional[List[Dict[str, Any]]]:\n",
        "    params = {\"ativo\": \"true\"}\n",
        "    dados = chamar_api(\"GET\", \"equipamento/list\", token, params=params, session=session)\n",
        "    if not dados:\n",
        "        return None\n",
        "    if isinstance(dados, list):\n",
        "        return dados\n",
        "    if isinstance(dados, dict) and \"items\" in dados:\n",
        "        return dados[\"items\"]\n",
        "    return [dados]\n",
        "\n",
        "# ============================================\n",
        "# AMOSTRAS: RESULTADOS (sampleResult/search) com CHUNK + paginação\n",
        "# ============================================\n",
        "\n",
        "def gerar_janelas_data(periodo_dias: int, chunk_dias: int) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Gera janelas [startDate, endDate] em ISO YYYY-MM-DD, do passado até hoje.\"\"\"\n",
        "    hoje = datetime.now().date()\n",
        "    inicio = hoje - timedelta(days=periodo_dias)\n",
        "    janelas = []\n",
        "    cursor = inicio\n",
        "    while cursor <= hoje:\n",
        "        fim_chunk = min(cursor + timedelta(days=chunk_dias - 1), hoje)\n",
        "        janelas.append((cursor.strftime(\"%Y-%m-%d\"), fim_chunk.strftime(\"%Y-%m-%d\")))\n",
        "        cursor = fim_chunk + timedelta(days=1)\n",
        "    return janelas\n",
        "\n",
        "def coletar_resultados(token: str, periodo_dias: int = PERIODO_DIAS,\n",
        "                       chunk_dias: int = CHUNK_DIAS,\n",
        "                       session: Optional[requests.Session] = None) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Coleta 100% dos resultados em janelas de 'chunk_dias', paginando até o fim.\n",
        "    Usa readingStatus=null (com filtro de data) e markRead=null (não marca como lidas).\n",
        "    \"\"\"\n",
        "    todos: List[Dict[str, Any]] = []\n",
        "    janelas = gerar_janelas_data(periodo_dias, chunk_dias)\n",
        "    print(f\"[Resultados] Janelas geradas: {len(janelas)} (de {janelas[0][0]} até {janelas[-1][1]})\")\n",
        "\n",
        "    for (data_inicio, data_fim) in janelas:\n",
        "        page = 1\n",
        "        print(f\"[Resultados] Janela {data_inicio} → {data_fim}\")\n",
        "        while True:\n",
        "            body = {\n",
        "                \"readingStatus\": None,   # null: todos (com filtro de data)\n",
        "                \"markRead\": None,        # null: não marcar como lidas no backfill\n",
        "                \"startDate\": data_inicio,\n",
        "                \"endDate\": data_fim,\n",
        "                \"page\": page,\n",
        "                \"pageSize\": PAGE_SIZE,\n",
        "            }\n",
        "            dados = chamar_api(\"POST\", \"sampleResult/search\", token, body=body, session=session)\n",
        "            if not dados:\n",
        "                print(f\"[Resultados] Sem dados ou falha na janela {data_inicio} → {data_fim}, página {page}.\")\n",
        "                break\n",
        "\n",
        "            if isinstance(dados, dict) and isinstance(dados.get(\"items\"), list):\n",
        "                itens = dados[\"items\"]\n",
        "            elif isinstance(dados, list):\n",
        "                itens = dados\n",
        "            else:\n",
        "                itens = [dados]\n",
        "\n",
        "            qtd = len(itens)\n",
        "            todos.extend(itens)\n",
        "            print(f\"[Resultados] {data_inicio} → {data_fim} | página {page} | itens {qtd} | acumulado {len(todos)}\")\n",
        "\n",
        "            if qtd < PAGE_SIZE:\n",
        "                break  # última página da janela\n",
        "            page += 1\n",
        "\n",
        "    return todos\n",
        "\n",
        "# ============================================\n",
        "# SALVAR CSV\n",
        "# ============================================\n",
        "\n",
        "def salvar_csv(dados: Any, nome: str) -> None:\n",
        "    ensure_dir(PASTA_SAIDA)\n",
        "    caminho = os.path.join(PASTA_SAIDA, nome)\n",
        "    if isinstance(dados, list):\n",
        "        df = pd.DataFrame(dados)\n",
        "    elif isinstance(dados, dict):\n",
        "        df = pd.DataFrame([dados])\n",
        "    else:\n",
        "        raise ValueError(\"Formato de dados não suportado para CSV.\")\n",
        "    df.to_csv(caminho, index=False, encoding=CSV_ENCODING, sep=CSV_SEPARADOR)\n",
        "    print(f\"Arquivo salvo: {caminho}\")\n",
        "\n",
        "# ============================================\n",
        "# EXECUÇÃO PRINCIPAL\n",
        "# ============================================\n",
        "\n",
        "def executar_rotina():\n",
        "    print(\"Iniciando coleta:\", datetime.now())\n",
        "    session = requests.Session()\n",
        "    token = autenticar(session=session)\n",
        "\n",
        "    # Equipamentos (ativos)\n",
        "    equipamentos = coletar_equipamentos(token, session=session)\n",
        "    if equipamentos:\n",
        "        salvar_csv(equipamentos, f\"equipamentos_{datetime.now().date()}.csv\")\n",
        "    else:\n",
        "        print(\"[Equipamentos] Nenhum dado retornado.\")\n",
        "\n",
        "    # Resultados de amostra (100% do último ano em janelas + paginação)\n",
        "    resultados = coletar_resultados(token, periodo_dias=PERIODO_DIAS, chunk_dias=CHUNK_DIAS, session=session)\n",
        "    if resultados:\n",
        "        salvar_csv(resultados, f\"resultados_{datetime.now().date()}.csv\")\n",
        "    else:\n",
        "        print(\"[Resultados] Nenhum dado retornado.\")\n",
        "\n",
        "    print(\"Finalizado:\", datetime.now())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ensure_dir(PASTA_SAIDA)\n",
        "    try:\n",
        "        executar_rotina()\n",
        "    except Exception as e:\n",
        "        print(\"Falha na execução:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNwpLTvbbDkm",
        "outputId": "ffd73114-3973-4561-999d-7ab2c1793244"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando coleta: 2026-01-13 17:34:22.389842\n",
            "[LOGIN] Status: 400 Bad Request | Content-Type: \n",
            "[LOGIN] Body (até 1000 chars): \n",
            "[LOGIN] Headers: {'Date': 'Tue, 13 Jan 2026 17:34:23 GMT'}\n",
            "[LOGIN] Autenticado com payload: ['username', 'password']\n",
            "[API] GET equipamento/list tentativa 1/3 Status: 405 Method Not Allowed | Content-Type: application/xml;charset=UTF-8\n",
            "[API] GET equipamento/list tentativa 1/3 Body (até 1000 chars): <Map><timestamp>1768325663774</timestamp><status>405</status><error>Method Not Allowed</error><path>/api/v1/equipamento/list</path></Map>\n",
            "[API] GET equipamento/list tentativa 1/3 Headers: {'Date': 'Tue, 13 Jan 2026 17:34:23 GMT'}\n",
            "[Equipamentos] Nenhum dado retornado.\n",
            "[Resultados] Janelas geradas: 12 (de 2025-01-13 até 2026-01-13)\n",
            "[Resultados] Janela 2025-01-13 → 2025-02-12\n",
            "[Resultados] 2025-01-13 → 2025-02-12 | página 1 | itens 1 | acumulado 1\n",
            "[Resultados] Janela 2025-02-13 → 2025-03-15\n",
            "[Resultados] 2025-02-13 → 2025-03-15 | página 1 | itens 1 | acumulado 2\n",
            "[Resultados] Janela 2025-03-16 → 2025-04-15\n",
            "[Resultados] 2025-03-16 → 2025-04-15 | página 1 | itens 1 | acumulado 3\n",
            "[Resultados] Janela 2025-04-16 → 2025-05-16\n",
            "[Resultados] 2025-04-16 → 2025-05-16 | página 1 | itens 1 | acumulado 4\n",
            "[Resultados] Janela 2025-05-17 → 2025-06-16\n",
            "[Resultados] 2025-05-17 → 2025-06-16 | página 1 | itens 1 | acumulado 5\n",
            "[Resultados] Janela 2025-06-17 → 2025-07-17\n",
            "[Resultados] 2025-06-17 → 2025-07-17 | página 1 | itens 1 | acumulado 6\n",
            "[Resultados] Janela 2025-07-18 → 2025-08-17\n",
            "[Resultados] 2025-07-18 → 2025-08-17 | página 1 | itens 1 | acumulado 7\n",
            "[Resultados] Janela 2025-08-18 → 2025-09-17\n",
            "[Resultados] 2025-08-18 → 2025-09-17 | página 1 | itens 1 | acumulado 8\n",
            "[Resultados] Janela 2025-09-18 → 2025-10-18\n",
            "[Resultados] 2025-09-18 → 2025-10-18 | página 1 | itens 1 | acumulado 9\n",
            "[Resultados] Janela 2025-10-19 → 2025-11-18\n",
            "[Resultados] 2025-10-19 → 2025-11-18 | página 1 | itens 1 | acumulado 10\n",
            "[Resultados] Janela 2025-11-19 → 2025-12-19\n",
            "[Resultados] 2025-11-19 → 2025-12-19 | página 1 | itens 1 | acumulado 11\n",
            "[Resultados] Janela 2025-12-20 → 2026-01-13\n",
            "[Resultados] 2025-12-20 → 2026-01-13 | página 1 | itens 1 | acumulado 12\n",
            "Arquivo salvo: /content/s360_export/resultados_2026-01-13.csv\n",
            "Finalizado: 2026-01-13 17:39:37.103465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Optional, Dict, Any, List, Tuple\n",
        "\n",
        "# ============================================\n",
        "# CONFIGURAÇÕES DA API\n",
        "# ============================================\n",
        "\n",
        "LOGIN_URL = \"https://integration.s360web.com/api/login\"\n",
        "API_BASE = \"https://integration.s360web.com/api/v1\"\n",
        "\n",
        "USER = os.getenv(\"S360_USER\", \"integracao.komatsu\")\n",
        "PASSWORD = os.getenv(\"S360_PASSWORD\", \"o8sqfl5h\")\n",
        "\n",
        "PASTA_SAIDA = \"/content/s360_export/\"\n",
        "PERIODO_DIAS = 365         # backfill de 1 ano\n",
        "CHUNK_DIAS = 31            # janelas mensais para cobrir 100%\n",
        "PAGE_SIZE = 500            # tamanho de página\n",
        "TIMEOUT = (10, 60)         # (connect, read)\n",
        "MAX_RETRIES = 3\n",
        "RETRY_BACKOFF = 2          # base exponencial\n",
        "SLEEP_ENTRE_CHAMADAS = 25  # orientação S360\n",
        "\n",
        "CSV_SEPARADOR = \",\"\n",
        "CSV_ENCODING = \"utf-8-sig\"\n",
        "\n",
        "# ============================================\n",
        "# UTILITÁRIOS\n",
        "# ============================================\n",
        "\n",
        "def ensure_dir(path: str) -> None:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def log_resp(r: requests.Response, prefix: str = \"\") -> None:\n",
        "    ct = r.headers.get(\"Content-Type\", \"\")\n",
        "    print(f\"{prefix}Status: {r.status_code} {r.reason} | Content-Type: {ct}\")\n",
        "    body = r.text or \"\"\n",
        "    print(f\"{prefix}Body (até 1000 chars): {body[:1000]}\")\n",
        "    importantes = ['date', 'server', 'x-request-id', 'x-correlation-id']\n",
        "    print(f\"{prefix}Headers: { {k: v for k, v in r.headers.items() if k.lower() in importantes} }\")\n",
        "\n",
        "def get(o: Dict[str, Any], path: str, default: Any = None) -> Any:\n",
        "    \"\"\"\n",
        "    Acesso seguro a objetos aninhados usando caminho com pontos.\n",
        "    Ex.: get(sample, 'equipment.model')\n",
        "    \"\"\"\n",
        "    cur = o\n",
        "    for p in path.split('.'):\n",
        "        if cur is None:\n",
        "            return default\n",
        "        if isinstance(cur, dict):\n",
        "            cur = cur.get(p, default)\n",
        "        else:\n",
        "            return default\n",
        "    return cur\n",
        "\n",
        "def normalize_decimal(value: Any) -> Tuple[Optional[float], str, bool]:\n",
        "    \"\"\"\n",
        "    Tenta converter strings como '24,921660', '11,80', '1,817' em float com ponto.\n",
        "    Mantém o texto original em 'clean' e informa se é numérico via 'is_num'.\n",
        "    Não força conversão para tokens como '<1', '23/21/15', '-', 'I.P'.\n",
        "    \"\"\"\n",
        "    if value is None:\n",
        "        return None, \"\", False\n",
        "    if isinstance(value, (int, float)):\n",
        "        return float(value), str(value), True\n",
        "    s = str(value).strip()\n",
        "    # Casos não-numéricos óbvios\n",
        "    if s in {\"-\", \"\", \"I.P\"} or \"/\" in s or s.startswith(\"<\") or s.startswith(\">\"):\n",
        "        return None, s, False\n",
        "    # Troca vírgula por ponto e remove espaços\n",
        "    s2 = s.replace(\",\", \".\")\n",
        "    # Mantém sinais e ponto; remove outros caracteres não numéricos\n",
        "    s2 = re.sub(r\"[^0-9\\.\\-eE]\", \"\", s2)\n",
        "    try:\n",
        "        num = float(s2)\n",
        "        return num, s, True\n",
        "    except ValueError:\n",
        "        return None, s, False\n",
        "\n",
        "def join_names(items: List[Dict[str, Any]], field_path: str = \"name\", sep: str = \" | \") -> str:\n",
        "    \"\"\"\n",
        "    Junta nomes de uma lista de objetos (e.g., testPackages) em uma string.\n",
        "    \"\"\"\n",
        "    vals = []\n",
        "    for it in items or []:\n",
        "        v = get(it, field_path)\n",
        "        if v:\n",
        "            vals.append(str(v))\n",
        "    return sep.join(vals)\n",
        "\n",
        "# ============================================\n",
        "# AUTENTICAÇÃO\n",
        "# ============================================\n",
        "\n",
        "def autenticar(session: Optional[requests.Session] = None) -> str:\n",
        "    sess = session or requests.Session()\n",
        "    payloads = [\n",
        "        {\"login\": USER, \"password\": PASSWORD},    # funciona no seu ambiente\n",
        "        {\"username\": USER, \"password\": PASSWORD}, # variação vista no dev portal\n",
        "        {\"email\": USER, \"password\": PASSWORD},\n",
        "    ]\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        for payload in payloads:\n",
        "            try:\n",
        "                r = sess.post(LOGIN_URL, json=payload, timeout=TIMEOUT)\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"[LOGIN] Falha de rede {attempt}/{MAX_RETRIES}: {e}\")\n",
        "                time.sleep(RETRY_BACKOFF ** attempt)\n",
        "                continue\n",
        "\n",
        "            if r.status_code == 200:\n",
        "                try:\n",
        "                    data = r.json()\n",
        "                except ValueError:\n",
        "                    log_resp(r, prefix=\"[LOGIN] \")\n",
        "                    raise RuntimeError(\"[LOGIN] Resposta não-JSON.\")\n",
        "                token = data.get(\"token\") or data.get(\"access_token\") or data.get(\"accessToken\") or data.get(\"jwt\")\n",
        "                if token:\n",
        "                    print(\"[LOGIN] Autenticado com payload:\", list(payload.keys()))\n",
        "                    return token\n",
        "                log_resp(r, prefix=\"[LOGIN] \")\n",
        "                raise RuntimeError(\"[LOGIN] Token ausente na resposta.\")\n",
        "            else:\n",
        "                log_resp(r, prefix=\"[LOGIN] \")\n",
        "\n",
        "        time.sleep(RETRY_BACKOFF ** attempt)\n",
        "\n",
        "    raise RuntimeError(\"[LOGIN] Não foi possível autenticar após múltiplas tentativas.\")\n",
        "\n",
        "# ============================================\n",
        "# CHAMADAS DE API (GET/POST) COM RETRY\n",
        "# ============================================\n",
        "\n",
        "def chamar_api(method: str, endpoint: str, token: str,\n",
        "               params: Optional[Dict[str, Any]] = None,\n",
        "               body: Optional[Dict[str, Any]] = None,\n",
        "               session: Optional[requests.Session] = None) -> Optional[Dict[str, Any]]:\n",
        "    sess = session or requests.Session()\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "    url = f\"{API_BASE.rstrip('/')}/{endpoint.lstrip('/')}\"\n",
        "\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            if method.upper() == \"GET\":\n",
        "                r = sess.get(url, headers=headers, params=params, timeout=TIMEOUT)\n",
        "            else:\n",
        "                r = sess.post(url, headers=headers, json=body, timeout=TIMEOUT)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"[API] Falha de rede em {method} {url} ({attempt}/{MAX_RETRIES}): {e}\")\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            try:\n",
        "                data = r.json()\n",
        "            except ValueError:\n",
        "                log_resp(r, prefix=\"[API] \")\n",
        "                print(\"[API] Resposta não-JSON; retornando None.\")\n",
        "                return None\n",
        "            time.sleep(SLEEP_ENTRE_CHAMADAS)  # orientação S360\n",
        "            return data\n",
        "\n",
        "        log_resp(r, prefix=f\"[API] {method} {endpoint} tentativa {attempt}/{MAX_RETRIES} \")\n",
        "        if r.status_code in (429, 500, 502, 503, 504):\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    print(f\"[API] Desistindo de {method} {endpoint} após {MAX_RETRIES} tentativas.\")\n",
        "    return None\n",
        "\n",
        "# ============================================\n",
        "# EQUIPAMENTOS (ativos)\n",
        "# ============================================\n",
        "\n",
        "def coletar_equipamentos(token: str, session: Optional[requests.Session] = None) -> Optional[List[Dict[str, Any]]]:\n",
        "    params = {\"ativo\": \"true\"}\n",
        "    dados = chamar_api(\"GET\", \"equipamento/list\", token, params=params, session=session)\n",
        "    if not dados:\n",
        "        return None\n",
        "    if isinstance(dados, list):\n",
        "        return dados\n",
        "    if isinstance(dados, dict) and \"items\" in dados:\n",
        "        return dados[\"items\"]\n",
        "    return [dados]\n",
        "\n",
        "# ============================================\n",
        "# RESULTADOS (sampleResult/search) com CHUNK + paginação\n",
        "# ============================================\n",
        "\n",
        "def gerar_janelas_data(periodo_dias: int, chunk_dias: int) -> List[Tuple[str, str]]:\n",
        "    hoje = datetime.now().date()\n",
        "    inicio = hoje - timedelta(days=periodo_dias)\n",
        "    janelas = []\n",
        "    cursor = inicio\n",
        "    while cursor <= hoje:\n",
        "        fim_chunk = min(cursor + timedelta(days=chunk_dias - 1), hoje)\n",
        "        janelas.append((cursor.strftime(\"%Y-%m-%d\"), fim_chunk.strftime(\"%Y-%m-%d\")))\n",
        "        cursor = fim_chunk + timedelta(days=1)\n",
        "    return janelas\n",
        "\n",
        "def coletar_resultados(token: str, periodo_dias: int = PERIODO_DIAS,\n",
        "                       chunk_dias: int = CHUNK_DIAS,\n",
        "                       session: Optional[requests.Session] = None) -> List[Dict[str, Any]]:\n",
        "    todos: List[Dict[str, Any]] = []\n",
        "    janelas = gerar_janelas_data(periodo_dias, chunk_dias)\n",
        "    print(f\"[Resultados] Janelas geradas: {len(janelas)} (de {janelas[0][0]} até {janelas[-1][1]})\")\n",
        "\n",
        "    for (data_inicio, data_fim) in janelas:\n",
        "        page = 1\n",
        "        print(f\"[Resultados] Janela {data_inicio} → {data_fim}\")\n",
        "        while True:\n",
        "            body = {\n",
        "                \"readingStatus\": None,   # null: todos (com filtro de data)\n",
        "                \"markRead\": None,        # null: não marcar como lidas no backfill\n",
        "                \"startDate\": data_inicio,\n",
        "                \"endDate\": data_fim,\n",
        "                \"page\": page,\n",
        "                \"pageSize\": PAGE_SIZE,\n",
        "            }\n",
        "            dados = chamar_api(\"POST\", \"sampleResult/search\", token, body=body, session=session)\n",
        "            if not dados:\n",
        "                print(f\"[Resultados] Sem dados ou falha na janela {data_inicio} → {data_fim}, página {page}.\")\n",
        "                break\n",
        "\n",
        "            if isinstance(dados, dict) and isinstance(dados.get(\"items\"), list):\n",
        "                itens = dados[\"items\"]\n",
        "            elif isinstance(dados, list):\n",
        "                itens = dados\n",
        "            else:\n",
        "                itens = [dados]\n",
        "\n",
        "            qtd = len(itens)\n",
        "            todos.extend(itens)\n",
        "            print(f\"[Resultados] {data_inicio} → {data_fim} | página {page} | itens {qtd} | acumulado {len(todos)}\")\n",
        "\n",
        "            if qtd < PAGE_SIZE:\n",
        "                break\n",
        "            page += 1\n",
        "\n",
        "    return todos\n",
        "\n",
        "# ============================================\n",
        "# ETL: FLATTEN (1 linha = 1 teste por amostra)\n",
        "# ============================================\n",
        "\n",
        "def flatten_resultados(resultados: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Transforma cada amostra em N linhas (uma por teste), com metadados completos.\n",
        "    Converte resultValue para número (quando possível), mantendo original.\n",
        "    \"\"\"\n",
        "    linhas: List[Dict[str, Any]] = []\n",
        "\n",
        "    for s in resultados or []:\n",
        "        # Metadados de nível amostra\n",
        "        sample_id         = s.get(\"id\")\n",
        "        sample_number     = s.get(\"sampleNumber\")\n",
        "        external_code     = s.get(\"externalCode\")\n",
        "        result_date       = s.get(\"resultDate\")\n",
        "        reading_status    = s.get(\"readingStatus\")\n",
        "\n",
        "        # validResult (status geral, avaliação e ação de inspeção)\n",
        "        vr_status         = get(s, \"validResult.resultStatus\")\n",
        "        vr_eval           = get(s, \"validResult.evaluation\")\n",
        "        vr_action         = get(s, \"validResult.inspectionAction\")\n",
        "\n",
        "        # Metadados de equipamento/cliente/site/compartimento\n",
        "        equip_model       = get(s, \"equipment.model\")\n",
        "        equip_serial      = get(s, \"equipment.serial\")\n",
        "        equip_tag         = get(s, \"equipment.tag\")\n",
        "        equip_family      = get(s, \"equipment.family.name\")\n",
        "        equip_maker       = get(s, \"equipment.maker.name\")\n",
        "        site_name         = get(s, \"site.name\") or get(s, \"equipment.site.name\")\n",
        "        site_ext_code     = get(s, \"site.externalCode\") or get(s, \"equipment.site.externalCode\")\n",
        "        customer_name     = get(s, \"customer.name\")\n",
        "        customer_id       = get(s, \"customer.id\")\n",
        "        operation_name    = get(s, \"operation.name\")\n",
        "        lab_name          = get(s, \"laboratory.name\")\n",
        "        payment_terms     = s.get(\"paymentTerms\")\n",
        "\n",
        "        comp_name         = get(s, \"compartment.name\") or get(s, \"collectionData.compartmentName\")\n",
        "        comp_type         = get(s, \"compartment.type.name\") or get(s, \"collectionData.compartmentType.name\")\n",
        "        comp_volume       = get(s, \"compartment.volume\")\n",
        "        coll_date_sampled = get(s, \"collectionData.dateSampled\")\n",
        "        coll_reg_date     = get(s, \"collectionData.registrationDate\")\n",
        "        coll_time_type    = get(s, \"collectionData.timeType\")\n",
        "        coll_fluid_time   = get(s, \"collectionData.fluidTime\")\n",
        "        coll_equipt_time  = get(s, \"collectionData.equipmentTime\")\n",
        "        oil_viscosity     = get(s, \"collectionData.oil.viscosity.name\")\n",
        "        oil_manufacturer  = get(s, \"collectionData.oil.manufacturer.name\")\n",
        "        oil_changed       = get(s, \"collectionData.oilChanged\")\n",
        "\n",
        "        test_packages     = join_names(s.get(\"testPackages\") or [], \"name\")\n",
        "\n",
        "        # Lista de testes por amostra\n",
        "        tests = s.get(\"testResults\") or []\n",
        "        if not tests:\n",
        "            # Ainda assim, registramos uma linha \"sem teste\" para rastreabilidade\n",
        "            linhas.append({\n",
        "                \"sampleId\": sample_id,\n",
        "                \"sampleNumber\": sample_number,\n",
        "                \"externalCode\": external_code,\n",
        "                \"resultDate\": result_date,\n",
        "                \"readingStatus\": reading_status,\n",
        "                \"validResultStatus\": vr_status,\n",
        "                \"validResultEvaluation\": vr_eval,\n",
        "                \"validResultInspectionAction\": vr_action,\n",
        "                \"equipmentModel\": equip_model,\n",
        "                \"equipmentSerial\": equip_serial,\n",
        "                \"equipmentTag\": equip_tag,\n",
        "                \"equipmentFamily\": equip_family,\n",
        "                \"equipmentMaker\": equip_maker,\n",
        "                \"siteName\": site_name,\n",
        "                \"siteExternalCode\": site_ext_code,\n",
        "                \"customerName\": customer_name,\n",
        "                \"customerId\": customer_id,\n",
        "                \"operationName\": operation_name,\n",
        "                \"laboratoryName\": lab_name,\n",
        "                \"paymentTerms\": payment_terms,\n",
        "                \"compartmentName\": comp_name,\n",
        "                \"compartmentType\": comp_type,\n",
        "                \"compartmentVolume\": comp_volume,\n",
        "                \"collectionDateSampled\": coll_date_sampled,\n",
        "                \"collectionRegistrationDate\": coll_reg_date,\n",
        "                \"collectionTimeType\": coll_time_type,\n",
        "                \"collectionFluidTime\": coll_fluid_time,\n",
        "                \"collectionEquipmentTime\": coll_equipt_time,\n",
        "                \"oilViscosity\": oil_viscosity,\n",
        "                \"oilManufacturer\": oil_manufacturer,\n",
        "                \"oilChanged\": oil_changed,\n",
        "                \"testGroup\": None,\n",
        "                \"testName\": None,\n",
        "                \"testAbbreviation\": None,\n",
        "                \"testUnitOfMeasure\": None,\n",
        "                \"testMethod\": None,\n",
        "                \"testValueType\": None,\n",
        "                \"testOrder\": None,\n",
        "                \"resultValue_raw\": None,\n",
        "                \"resultValue_num\": None,\n",
        "                \"resultValue_is_numeric\": False,\n",
        "                \"resultStatus\": None,\n",
        "                \"testPackages\": test_packages,\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        for tr in tests:\n",
        "            test_group       = get(tr, \"test.testGroup.name\")\n",
        "            test_name        = get(tr, \"test.translation.name\")\n",
        "            test_abbrev      = get(tr, \"test.translation.abbreviation\")\n",
        "            test_uom         = get(tr, \"test.translation.unitOfMeasure\")\n",
        "            test_method      = get(tr, \"test.translation.method\")\n",
        "            test_value_type  = get(tr, \"test.valueType\")\n",
        "            test_order       = get(tr, \"test.order\")\n",
        "            result_status    = tr.get(\"resultStatus\")\n",
        "            result_value     = tr.get(\"resultValue\")\n",
        "\n",
        "            num, raw, is_num = normalize_decimal(result_value)\n",
        "\n",
        "            linhas.append({\n",
        "                # Amostra\n",
        "                \"sampleId\": sample_id,\n",
        "                \"sampleNumber\": sample_number,\n",
        "                \"externalCode\": external_code,\n",
        "                \"resultDate\": result_date,\n",
        "                \"readingStatus\": reading_status,\n",
        "                \"validResultStatus\": vr_status,\n",
        "                \"validResultEvaluation\": vr_eval,\n",
        "                \"validResultInspectionAction\": vr_action,\n",
        "\n",
        "                # Equip/cliente/site\n",
        "                \"equipmentModel\": equip_model,\n",
        "                \"equipmentSerial\": equip_serial,\n",
        "                \"equipmentTag\": equip_tag,\n",
        "                \"equipmentFamily\": equip_family,\n",
        "                \"equipmentMaker\": equip_maker,\n",
        "                \"siteName\": site_name,\n",
        "                \"siteExternalCode\": site_ext_code,\n",
        "                \"customerName\": customer_name,\n",
        "                \"customerId\": customer_id,\n",
        "                \"operationName\": operation_name,\n",
        "                \"laboratoryName\": lab_name,\n",
        "                \"paymentTerms\": payment_terms,\n",
        "\n",
        "                # Compartimento / coleta / óleo\n",
        "                \"compartmentName\": comp_name,\n",
        "                \"compartmentType\": comp_type,\n",
        "                \"compartmentVolume\": comp_volume,\n",
        "                \"collectionDateSampled\": coll_date_sampled,\n",
        "                \"collectionRegistrationDate\": coll_reg_date,\n",
        "                \"collectionTimeType\": coll_time_type,\n",
        "                \"collectionFluidTime\": coll_fluid_time,\n",
        "                \"collectionEquipmentTime\": coll_equipt_time,\n",
        "                \"oilViscosity\": oil_viscosity,\n",
        "                \"oilManufacturer\": oil_manufacturer,\n",
        "                \"oilChanged\": oil_changed,\n",
        "\n",
        "                # Teste\n",
        "                \"testGroup\": test_group,\n",
        "                \"testName\": test_name,\n",
        "                \"testAbbreviation\": test_abbrev,\n",
        "                \"testUnitOfMeasure\": test_uom,\n",
        "                \"testMethod\": test_method,\n",
        "                \"testValueType\": test_value_type,\n",
        "                \"testOrder\": test_order,\n",
        "                \"resultValue_raw\": raw,\n",
        "                \"resultValue_num\": num,\n",
        "                \"resultValue_is_numeric\": is_num,\n",
        "                \"resultStatus\": result_status,\n",
        "\n",
        "                # Pacotes de teste (lista)\n",
        "                \"testPackages\": test_packages,\n",
        "            })\n",
        "\n",
        "    return linhas\n",
        "\n",
        "# ============================================\n",
        "# SALVAR CSV\n",
        "# ============================================\n",
        "\n",
        "def salvar_csv(dados: Any, nome: str) -> None:\n",
        "    ensure_dir(PASTA_SAIDA)\n",
        "    caminho = os.path.join(PASTA_SAIDA, nome)\n",
        "    if isinstance(dados, list):\n",
        "        df = pd.DataFrame(dados)\n",
        "    elif isinstance(dados, dict):\n",
        "        df = pd.DataFrame([dados])\n",
        "    else:\n",
        "        raise ValueError(\"Formato de dados não suportado para CSV.\")\n",
        "    df.to_csv(caminho, index=False, encoding=CSV_ENCODING, sep=CSV_SEPARADOR)\n",
        "    print(f\"Arquivo salvo: {caminho}\")\n",
        "\n",
        "# ============================================\n",
        "# EXECUÇÃO PRINCIPAL\n",
        "# ============================================\n",
        "\n",
        "def executar_rotina():\n",
        "    print(\"Iniciando coleta:\", datetime.now())\n",
        "    session = requests.Session()\n",
        "    token = autenticar(session=session)\n",
        "\n",
        "    # Equipamentos (ativos)\n",
        "    equipamentos = coletar_equipamentos(token, session=session)\n",
        "    if equipamentos:\n",
        "        salvar_csv(equipamentos, f\"equipamentos_{datetime.now().date()}.csv\")\n",
        "    else:\n",
        "        print(\"[Equipamentos] Nenhum dado retornado.\")\n",
        "\n",
        "    # Resultados (100% do último ano em janelas + paginação)\n",
        "    resultados = coletar_resultados(token, periodo_dias=PERIODO_DIAS, chunk_dias=CHUNK_DIAS, session=session)\n",
        "    if resultados:\n",
        "        # Salva o bruto (como referência/origem)\n",
        "        salvar_csv(resultados, f\"resultados_{datetime.now().date()}.csv\")\n",
        "\n",
        "        # ETL: flatten → uma linha por teste (tabular para BI/Excel)\n",
        "        resultados_flat = flatten_resultados(resultados)\n",
        "        if resultados_flat:\n",
        "            salvar_csv(resultados_flat, f\"resultados_flat_{datetime.now().date()}.csv\")\n",
        "        else:\n",
        "            print(\"[Flatten] Nenhuma linha gerada (lista de testes vazia em todas as amostras).\")\n",
        "    else:\n",
        "        print(\"[Resultados] Nenhum dado retornado.\")\n",
        "\n",
        "    print(\"Finalizado:\", datetime.now())\n",
        "\n",
        "# ============================================\n",
        "# MAIN\n",
        "# ============================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ensure_dir(PASTA_SAIDA)\n",
        "    try:\n",
        "        executar_rotina()\n",
        "    except Exception as e:\n",
        "        print(\"Falha na execução:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT19qCAUGZqs",
        "outputId": "46523c7b-71e2-4b12-98b6-309b59140c73"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando coleta: 2026-01-13 22:45:59.266049\n",
            "[LOGIN] Status: 400 Bad Request | Content-Type: \n",
            "[LOGIN] Body (até 1000 chars): \n",
            "[LOGIN] Headers: {'Date': 'Tue, 13 Jan 2026 22:45:59 GMT'}\n",
            "[LOGIN] Autenticado com payload: ['username', 'password']\n",
            "[API] GET equipamento/list tentativa 1/3 Status: 405 Method Not Allowed | Content-Type: application/xml;charset=UTF-8\n",
            "[API] GET equipamento/list tentativa 1/3 Body (até 1000 chars): <Map><timestamp>1768344359654</timestamp><status>405</status><error>Method Not Allowed</error><path>/api/v1/equipamento/list</path></Map>\n",
            "[API] GET equipamento/list tentativa 1/3 Headers: {'Date': 'Tue, 13 Jan 2026 22:45:59 GMT'}\n",
            "[Equipamentos] Nenhum dado retornado.\n",
            "[Resultados] Janelas geradas: 12 (de 2025-01-13 até 2026-01-13)\n",
            "[Resultados] Janela 2025-01-13 → 2025-02-12\n",
            "[Resultados] 2025-01-13 → 2025-02-12 | página 1 | itens 1 | acumulado 1\n",
            "[Resultados] Janela 2025-02-13 → 2025-03-15\n",
            "[Resultados] 2025-02-13 → 2025-03-15 | página 1 | itens 1 | acumulado 2\n",
            "[Resultados] Janela 2025-03-16 → 2025-04-15\n",
            "[Resultados] 2025-03-16 → 2025-04-15 | página 1 | itens 1 | acumulado 3\n",
            "[Resultados] Janela 2025-04-16 → 2025-05-16\n",
            "[Resultados] 2025-04-16 → 2025-05-16 | página 1 | itens 1 | acumulado 4\n",
            "[Resultados] Janela 2025-05-17 → 2025-06-16\n",
            "[Resultados] 2025-05-17 → 2025-06-16 | página 1 | itens 1 | acumulado 5\n",
            "[Resultados] Janela 2025-06-17 → 2025-07-17\n",
            "[Resultados] 2025-06-17 → 2025-07-17 | página 1 | itens 1 | acumulado 6\n",
            "[Resultados] Janela 2025-07-18 → 2025-08-17\n",
            "[Resultados] 2025-07-18 → 2025-08-17 | página 1 | itens 1 | acumulado 7\n",
            "[Resultados] Janela 2025-08-18 → 2025-09-17\n",
            "[Resultados] 2025-08-18 → 2025-09-17 | página 1 | itens 1 | acumulado 8\n",
            "[Resultados] Janela 2025-09-18 → 2025-10-18\n",
            "[Resultados] 2025-09-18 → 2025-10-18 | página 1 | itens 1 | acumulado 9\n",
            "[Resultados] Janela 2025-10-19 → 2025-11-18\n",
            "[Resultados] 2025-10-19 → 2025-11-18 | página 1 | itens 1 | acumulado 10\n",
            "[Resultados] Janela 2025-11-19 → 2025-12-19\n",
            "[Resultados] 2025-11-19 → 2025-12-19 | página 1 | itens 1 | acumulado 11\n",
            "[Resultados] Janela 2025-12-20 → 2026-01-13\n",
            "[Resultados] 2025-12-20 → 2026-01-13 | página 1 | itens 1 | acumulado 12\n",
            "Arquivo salvo: /content/s360_export/resultados_2026-01-13.csv\n",
            "Arquivo salvo: /content/s360_export/resultados_flat_2026-01-13.csv\n",
            "Finalizado: 2026-01-13 22:51:08.404899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import ast\n",
        "import requests\n",
        "import pandas as pd\n",
        "from csv import QUOTE_MINIMAL\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Optional, Dict, Any, List, Tuple\n",
        "\n",
        "# ============================================\n",
        "# CONFIGURAÇÕES DA API (conforme solicitado)\n",
        "# ============================================\n",
        "\n",
        "LOGIN_URL = \"https://integration.s360web.com/api/login\"\n",
        "API_BASE  = \"https://integration.s360web.com/api/v1\"\n",
        "\n",
        "USER     = os.getenv(\"S360_USER\", \"integracao.komatsu\")\n",
        "PASSWORD = os.getenv(\"S360_PASSWORD\", \"o8sqfl5h\")\n",
        "\n",
        "PASTA_SAIDA   = \"/content/s360_export/\"\n",
        "PERIODO_DIAS  = 365        # backfill de 1 ano\n",
        "CHUNK_DIAS    = 31         # janelas mensais para cobrir 100%\n",
        "PAGE_SIZE     = 500        # tamanho de página\n",
        "TIMEOUT       = (10, 60)   # (connect, read)\n",
        "MAX_RETRIES   = 3\n",
        "RETRY_BACKOFF = 2          # base exponencial\n",
        "SLEEP_ENTRE_CHAMADAS = 25  # orientação S360\n",
        "\n",
        "# Saída CSV (você pediu vírgula)\n",
        "CSV_SEPARADOR = \",\"\n",
        "CSV_ENCODING  = \"utf-8-sig\"\n",
        "\n",
        "# ============================================\n",
        "# CONFIGURAÇÕES ADICIONAIS\n",
        "# ============================================\n",
        "\n",
        "# Ordem opcional de colunas (None = não reordena)\n",
        "COL_ORDER: Optional[List[str]] = None\n",
        "\n",
        "# Modo de ingestão: \"api\" (padrão) ou \"csv\" (processa arquivo com coluna 'results')\n",
        "MODE     = os.getenv(\"MODE\", \"api\").lower().strip()\n",
        "SRC_FILE = os.getenv(\"SRC_FILE\", \"\").strip()\n",
        "\n",
        "# Permitir campos longos (para coluna 'results' quando o modo é csv)\n",
        "try:\n",
        "    csv.field_size_limit(sys.maxsize)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ============================================\n",
        "# UTILITÁRIOS\n",
        "# ============================================\n",
        "\n",
        "def ensure_dir(path: str) -> None:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def log_resp(r: requests.Response, prefix: str = \"\") -> None:\n",
        "    ct = r.headers.get(\"Content-Type\", \"\")\n",
        "    print(f\"{prefix}Status: {r.status_code} {r.reason} | Content-Type: {ct}\")\n",
        "    body = r.text or \"\"\n",
        "    print(f\"{prefix}Body (até 1000 chars): {body[:1000]}\")\n",
        "    importantes = ['date', 'server', 'x-request-id', 'x-correlation-id']\n",
        "    print(f\"{prefix}Headers: { {k: v for k, v in r.headers.items() if k.lower() in importantes} }\")\n",
        "\n",
        "def get(o: Dict[str, Any], path: str, default: Any = \"\") -> Any:\n",
        "    \"\"\"\n",
        "    Acesso seguro 'a.b.c'. Retorna '' por padrão (excel-friendly).\n",
        "    \"\"\"\n",
        "    cur = o\n",
        "    for p in path.split('.'):\n",
        "        if cur is None:\n",
        "            return default\n",
        "        if isinstance(cur, dict):\n",
        "            cur = cur.get(p, default)\n",
        "        else:\n",
        "            return default\n",
        "    return cur if cur is not None else default\n",
        "\n",
        "def normalize_decimal(value: Any) -> Tuple[Optional[float], str, bool]:\n",
        "    \"\"\"\n",
        "    Converte '24,921660' -> 24.92166. Mantém original em 'raw'.\n",
        "    Não converte tokens: '<1', '23/21/15', '-', 'I.P'.\n",
        "    \"\"\"\n",
        "    if value is None:\n",
        "        return None, \"\", False\n",
        "    if isinstance(value, (int, float)):\n",
        "        return float(value), str(value), True\n",
        "    s = str(value).strip()\n",
        "    if s in {\"-\", \"\", \"I.P\"} or \"/\" in s or s.startswith(\"<\") or s.startswith(\">\"):\n",
        "        return None, s, False\n",
        "    s2 = s.replace(\",\", \".\")\n",
        "    s2 = re.sub(r\"[^0-9\\.\\-eE]\", \"\", s2)\n",
        "    try:\n",
        "        return float(s2), s, True\n",
        "    except ValueError:\n",
        "        return None, s, False\n",
        "\n",
        "def join_names(items: List[Dict[str, Any]], field_path: str = \"name\", sep: str = \" | \") -> str:\n",
        "    vals = []\n",
        "    for it in items or []:\n",
        "        v = get(it, field_path)\n",
        "        if v:\n",
        "            vals.append(str(v))\n",
        "    return sep.join(vals)\n",
        "\n",
        "def fix_mojibake(s: Any) -> Any:\n",
        "    \"\"\"Corrige acentuação quebrada típica (Ã©, Ã§, etc.) quando aplicável.\"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return s\n",
        "    try:\n",
        "        return s.encode(\"latin1\").decode(\"utf-8\")\n",
        "    except Exception:\n",
        "        return s\n",
        "\n",
        "def aplicar_ordem_colunas(df: pd.DataFrame, col_order: Optional[List[str]] = None) -> pd.DataFrame:\n",
        "    if not col_order:\n",
        "        return df\n",
        "    keep = [c for c in col_order if c in df.columns]\n",
        "    extra = [c for c in df.columns if c not in keep]\n",
        "    return df[keep + extra]\n",
        "\n",
        "def detectar_sep_csv(src_file: str) -> str:\n",
        "    \"\"\"\n",
        "    Detecta automaticamente o delimitador do CSV de entrada (';' ou ',').\n",
        "    Usa a primeira linha não vazia para decidir.\n",
        "    \"\"\"\n",
        "    with open(src_file, \"r\", encoding=CSV_ENCODING, errors=\"replace\") as f:\n",
        "        for line in f:\n",
        "            ln = line.strip()\n",
        "            if not ln:\n",
        "                continue\n",
        "            # conta ocorrências\n",
        "            sc = ln.count(\";\")\n",
        "            cm = ln.count(\",\")\n",
        "            if sc > cm:\n",
        "                return \";\"\n",
        "            elif cm > sc:\n",
        "                return \",\"\n",
        "            # empate: tenta ';' por padrão (mais comum pt-BR)\n",
        "            return \";\"\n",
        "    # default seguro\n",
        "    return \";\"\n",
        "\n",
        "# ============================================\n",
        "# AUTENTICAÇÃO\n",
        "# ============================================\n",
        "\n",
        "def autenticar(session: Optional[requests.Session] = None) -> str:\n",
        "    sess = session or requests.Session()\n",
        "    payloads = [\n",
        "        {\"login\": USER,     \"password\": PASSWORD},\n",
        "        {\"username\": USER,  \"password\": PASSWORD},\n",
        "        {\"email\": USER,     \"password\": PASSWORD},\n",
        "    ]\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        for payload in payloads:\n",
        "            try:\n",
        "                r = sess.post(LOGIN_URL, json=payload, timeout=TIMEOUT)\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"[LOGIN] Falha de rede {attempt}/{MAX_RETRIES}: {e}\")\n",
        "                time.sleep(RETRY_BACKOFF ** attempt)\n",
        "                continue\n",
        "\n",
        "            if r.status_code == 200:\n",
        "                try:\n",
        "                    data = r.json()\n",
        "                except ValueError:\n",
        "                    log_resp(r, prefix=\"[LOGIN] \")\n",
        "                    raise RuntimeError(\"[LOGIN] Resposta não-JSON.\")\n",
        "                token = data.get(\"token\") or data.get(\"access_token\") \\\n",
        "                        or data.get(\"accessToken\") or data.get(\"jwt\")\n",
        "                if token:\n",
        "                    print(\"[LOGIN] Autenticado com payload:\", list(payload.keys()))\n",
        "                    return token\n",
        "                log_resp(r, prefix=\"[LOGIN] \")\n",
        "                raise RuntimeError(\"[LOGIN] Token ausente na resposta.\")\n",
        "            else:\n",
        "                log_resp(r, prefix=\"[LOGIN] \")\n",
        "        time.sleep(RETRY_BACKOFF ** attempt)\n",
        "    raise RuntimeError(\"[LOGIN] Não foi possível autenticar após múltiplas tentativas.\")\n",
        "\n",
        "# ============================================\n",
        "# CHAMADAS DE API (GET/POST) COM RETRY\n",
        "# ============================================\n",
        "\n",
        "def chamar_api(method: str, endpoint: str, token: str,\n",
        "               params: Optional[Dict[str, Any]] = None,\n",
        "               body: Optional[Dict[str, Any]] = None,\n",
        "               session: Optional[requests.Session] = None) -> Optional[Dict[str, Any]]:\n",
        "    sess = session or requests.Session()\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "    url = f\"{API_BASE.rstrip('/')}/{endpoint.lstrip('/')}\"\n",
        "\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            if method.upper() == \"GET\":\n",
        "                r = sess.get(url, headers=headers, params=params, timeout=TIMEOUT)\n",
        "            else:\n",
        "                r = sess.post(url, headers=headers, json=body, timeout=TIMEOUT)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"[API] Falha de rede em {method} {url} ({attempt}/{MAX_RETRIES}): {e}\")\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            try:\n",
        "                data = r.json()\n",
        "            except ValueError:\n",
        "                log_resp(r, prefix=\"[API] \")\n",
        "                print(\"[API] Resposta não-JSON; retornando None.\")\n",
        "                return None\n",
        "            time.sleep(SLEEP_ENTRE_CHAMADAS)\n",
        "            return data\n",
        "\n",
        "        log_resp(r, prefix=f\"[API] {method} {endpoint} tentativa {attempt}/{MAX_RETRIES} \")\n",
        "        if r.status_code in (429, 500, 502, 503, 504):\n",
        "            time.sleep(RETRY_BACKOFF ** attempt)\n",
        "            continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    print(f\"[API] Desistindo de {method} {endpoint} após {MAX_RETRIES} tentativas.\")\n",
        "    return None\n",
        "\n",
        "# ============================================\n",
        "# EQUIPAMENTOS (ativos)\n",
        "# ============================================\n",
        "\n",
        "def coletar_equipamentos(token: str, session: Optional[requests.Session] = None) -> Optional[List[Dict[str, Any]]]:\n",
        "    params = {\"ativo\": \"true\"}\n",
        "    dados = chamar_api(\"GET\", \"equipamento/list\", token, params=params, session=session)\n",
        "    if not dados:\n",
        "        return None\n",
        "    if isinstance(dados, list):\n",
        "        return dados\n",
        "    if isinstance(dados, dict) and \"items\" in dados:\n",
        "        return dados[\"items\"]\n",
        "    return [dados]\n",
        "\n",
        "# ============================================\n",
        "# RESULTADOS (sampleResult/search) com CHUNK + paginação\n",
        "# ============================================\n",
        "\n",
        "def gerar_janelas_data(periodo_dias: int, chunk_dias: int) -> List[Tuple[str, str]]:\n",
        "    hoje = datetime.now().date()\n",
        "    inicio = hoje - timedelta(days=periodo_dias)\n",
        "    janelas = []\n",
        "    cursor = inicio\n",
        "    while cursor <= hoje:\n",
        "        fim_chunk = min(cursor + timedelta(days=chunk_dias - 1), hoje)\n",
        "        janelas.append((cursor.strftime(\"%Y-%m-%d\"), fim_chunk.strftime(\"%Y-%m-%d\")))\n",
        "        cursor = fim_chunk + timedelta(days=1)\n",
        "    return janelas\n",
        "\n",
        "def coletar_resultados(token: str, periodo_dias: int = PERIODO_DIAS,\n",
        "                       chunk_dias: int = CHUNK_DIAS,\n",
        "                       session: Optional[requests.Session] = None) -> List[Dict[str, Any]]:\n",
        "    todos: List[Dict[str, Any]] = []\n",
        "    janelas = gerar_janelas_data(periodo_dias, chunk_dias)\n",
        "    print(f\"[Resultados] Janelas geradas: {len(janelas)} (de {janelas[0][0]} até {janelas[-1][1]})\")\n",
        "\n",
        "    for (data_inicio, data_fim) in janelas:\n",
        "        page = 1\n",
        "        print(f\"[Resultados] Janela {data_inicio} → {data_fim}\")\n",
        "        while True:\n",
        "            body = {\n",
        "                \"readingStatus\": None,\n",
        "                \"markRead\": None,\n",
        "                \"startDate\": data_inicio,\n",
        "                \"endDate\": data_fim,\n",
        "                \"page\": page,\n",
        "                \"pageSize\": PAGE_SIZE,\n",
        "            }\n",
        "            dados = chamar_api(\"POST\", \"sampleResult/search\", token, body=body, session=session)\n",
        "            if not dados:\n",
        "                print(f\"[Resultados] Sem dados ou falha na janela {data_inicio} → {data_fim}, página {page}.\")\n",
        "                break\n",
        "\n",
        "            if isinstance(dados, dict) and isinstance(dados.get(\"items\"), list):\n",
        "                itens = dados[\"items\"]\n",
        "            elif isinstance(dados, list):\n",
        "                itens = dados\n",
        "            else:\n",
        "                itens = [dados]\n",
        "\n",
        "            qtd = len(itens)\n",
        "            todos.extend(itens)\n",
        "            print(f\"[Resultados] {data_inicio} → {data_fim} | pág {page} | itens {qtd} | acumulado {len(todos)}\")\n",
        "\n",
        "            if qtd < PAGE_SIZE:\n",
        "                break\n",
        "            page += 1\n",
        "\n",
        "    return todos\n",
        "\n",
        "# ============================================\n",
        "# ETL: FLATTEN (1 linha = 1 teste por amostra)\n",
        "# ============================================\n",
        "\n",
        "def flatten_resultados(resultados: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    linhas: List[Dict[str, Any]] = []\n",
        "\n",
        "    for s in resultados or []:\n",
        "        # Metadados da amostra\n",
        "        sample_id         = s.get(\"id\", \"\")\n",
        "        sample_number     = s.get(\"sampleNumber\", \"\")\n",
        "        external_code     = s.get(\"externalCode\", \"\")\n",
        "        result_date       = s.get(\"resultDate\", \"\")\n",
        "        reading_status    = s.get(\"readingStatus\", \"\")\n",
        "\n",
        "        vr_status         = get(s, \"validResult.resultStatus\")\n",
        "        vr_eval           = fix_mojibake(get(s, \"validResult.evaluation\"))\n",
        "        vr_action         = fix_mojibake(get(s, \"validResult.inspectionAction\"))\n",
        "\n",
        "        # Equip/cliente/site/compartimento\n",
        "        equip_model       = get(s, \"equipment.model\")\n",
        "        equip_serial      = get(s, \"equipment.serial\")\n",
        "        equip_tag         = get(s, \"equipment.tag\")\n",
        "        equip_family      = fix_mojibake(get(s, \"equipment.family.name\"))\n",
        "        equip_maker       = get(s, \"equipment.maker.name\")\n",
        "\n",
        "        site_name         = fix_mojibake(get(s, \"site.name\") or get(s, \"equipment.site.name\"))\n",
        "        site_ext_code     = get(s, \"site.externalCode\") or get(s, \"equipment.site.externalCode\")\n",
        "\n",
        "        customer_name     = fix_mojibake(get(s, \"customer.name\"))\n",
        "        customer_id       = get(s, \"customer.id\")\n",
        "        operation_name    = get(s, \"operation.name\")\n",
        "        lab_name          = fix_mojibake(get(s, \"laboratory.name\"))\n",
        "        payment_terms     = s.get(\"paymentTerms\", \"\")\n",
        "\n",
        "        comp_name         = fix_mojibake(get(s, \"compartment.name\") or get(s, \"collectionData.compartmentName\"))\n",
        "        comp_type         = fix_mojibake(get(s, \"compartment.type.name\") or get(s, \"collectionData.compartmentType.name\"))\n",
        "        comp_volume       = get(s, \"compartment.volume\")\n",
        "\n",
        "        coll_date_sampled = get(s, \"collectionData.dateSampled\")\n",
        "        coll_reg_date     = get(s, \"collectionData.registrationDate\")\n",
        "        coll_time_type    = get(s, \"collectionData.timeType\")\n",
        "        coll_fluid_time   = get(s, \"collectionData.fluidTime\")\n",
        "        coll_equipt_time  = get(s, \"collectionData.equipmentTime\")\n",
        "        oil_viscosity     = get(s, \"collectionData.oil.viscosity.name\")\n",
        "        oil_manufacturer  = get(s, \"collectionData.oil.manufacturer.name\")\n",
        "        oil_changed       = get(s, \"collectionData.oilChanged\")\n",
        "\n",
        "        test_packages     = fix_mojibake(join_names(s.get(\"testPackages\") or [], \"name\"))\n",
        "\n",
        "        tests = s.get(\"testResults\") or []\n",
        "        if not tests:\n",
        "            # Linha de rastreabilidade (sem testes)\n",
        "            linhas.append({\n",
        "                \"sampleId\": sample_id, \"sampleNumber\": sample_number, \"externalCode\": external_code,\n",
        "                \"resultDate\": result_date, \"readingStatus\": reading_status,\n",
        "                \"validResultStatus\": vr_status, \"validResultEvaluation\": vr_eval, \"validResultInspectionAction\": vr_action,\n",
        "                \"equipmentModel\": equip_model, \"equipmentSerial\": equip_serial, \"equipmentTag\": equip_tag,\n",
        "                \"equipmentFamily\": equip_family, \"equipmentMaker\": equip_maker,\n",
        "                \"siteName\": site_name, \"siteExternalCode\": site_ext_code,\n",
        "                \"customerName\": customer_name, \"customerId\": customer_id,\n",
        "                \"operationName\": operation_name, \"laboratoryName\": lab_name,\n",
        "                \"paymentTerms\": payment_terms,\n",
        "                \"compartmentName\": comp_name, \"compartmentType\": comp_type, \"compartmentVolume\": comp_volume,\n",
        "                \"collectionDateSampled\": coll_date_sampled, \"collectionRegistrationDate\": coll_reg_date,\n",
        "                \"collectionTimeType\": coll_time_type, \"collectionFluidTime\": coll_fluid_time,\n",
        "                \"collectionEquipmentTime\": coll_equipt_time, \"oilViscosity\": oil_viscosity,\n",
        "                \"oilManufacturer\": oil_manufacturer, \"oilChanged\": oil_changed,\n",
        "                \"testGroup\": \"\", \"testName\": \"\", \"testAbbreviation\": \"\", \"testUnitOfMeasure\": \"\",\n",
        "                \"testMethod\": \"\", \"testValueType\": \"\", \"testOrder\": \"\",\n",
        "                \"resultValue_raw\": \"\", \"resultValue_num\": None, \"resultValue_is_numeric\": False,\n",
        "                \"resultStatus\": \"\", \"testPackages\": test_packages\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        for tr in tests:\n",
        "            test_group       = fix_mojibake(get(tr, \"test.testGroup.name\"))\n",
        "            test_name        = fix_mojibake(get(tr, \"test.translation.name\"))\n",
        "            test_abbrev      = fix_mojibake(get(tr, \"test.translation.abbreviation\"))\n",
        "            test_uom         = fix_mojibake(get(tr, \"test.translation.unitOfMeasure\"))\n",
        "            test_method      = fix_mojibake(get(tr, \"test.translation.method\"))\n",
        "            test_value_type  = get(tr, \"test.valueType\")\n",
        "            test_order       = get(tr, \"test.order\")\n",
        "            result_status    = tr.get(\"resultStatus\", \"\")\n",
        "            result_value     = tr.get(\"resultValue\", \"\")\n",
        "\n",
        "            num, raw, is_num = normalize_decimal(result_value)\n",
        "\n",
        "            linhas.append({\n",
        "                \"sampleId\": sample_id, \"sampleNumber\": sample_number, \"externalCode\": external_code,\n",
        "                \"resultDate\": result_date, \"readingStatus\": reading_status,\n",
        "                \"validResultStatus\": vr_status, \"validResultEvaluation\": vr_eval, \"validResultInspectionAction\": vr_action,\n",
        "\n",
        "                \"equipmentModel\": equip_model, \"equipmentSerial\": equip_serial, \"equipmentTag\": equip_tag,\n",
        "                \"equipmentFamily\": equip_family, \"equipmentMaker\": equip_maker,\n",
        "                \"siteName\": site_name, \"siteExternalCode\": site_ext_code,\n",
        "                \"customerName\": customer_name, \"customerId\": customer_id,\n",
        "                \"operationName\": operation_name, \"laboratoryName\": lab_name,\n",
        "                \"paymentTerms\": payment_terms,\n",
        "\n",
        "                \"compartmentName\": comp_name, \"compartmentType\": comp_type, \"compartmentVolume\": comp_volume,\n",
        "                \"collectionDateSampled\": coll_date_sampled, \"collectionRegistrationDate\": coll_reg_date,\n",
        "                \"collectionTimeType\": coll_time_type, \"collectionFluidTime\": coll_fluid_time,\n",
        "                \"collectionEquipmentTime\": coll_equipt_time, \"oilViscosity\": oil_viscosity,\n",
        "                \"oilManufacturer\": oil_manufacturer, \"oilChanged\": oil_changed,\n",
        "\n",
        "                \"testGroup\": test_group, \"testName\": test_name, \"testAbbreviation\": test_abbrev,\n",
        "                \"testUnitOfMeasure\": test_uom, \"testMethod\": test_method,\n",
        "                \"testValueType\": test_value_type, \"testOrder\": test_order,\n",
        "                \"resultValue_raw\": raw, \"resultValue_num\": num, \"resultValue_is_numeric\": is_num,\n",
        "                \"resultStatus\": result_status,\n",
        "                \"testPackages\": test_packages,\n",
        "            })\n",
        "\n",
        "    return linhas\n",
        "\n",
        "# ============================================\n",
        "# SALVAR CSV\n",
        "# ============================================\n",
        "\n",
        "def salvar_csv_table(df: pd.DataFrame, nome: str, col_order: Optional[List[str]] = COL_ORDER) -> None:\n",
        "    ensure_dir(PASTA_SAIDA)\n",
        "    caminho = os.path.join(PASTA_SAIDA, nome)\n",
        "    df2 = aplicar_ordem_colunas(df, col_order).fillna(\"\")\n",
        "    df2.to_csv(\n",
        "        caminho,\n",
        "        index=False,\n",
        "        encoding=CSV_ENCODING,\n",
        "        sep=CSV_SEPARADOR,\n",
        "        quoting=QUOTE_MINIMAL  # MINIMAL já cita campos com vírgula\n",
        "    )\n",
        "    print(f\"[CSV] Salvo: {caminho}\")\n",
        "\n",
        "# ============================================\n",
        "# VALIDAÇÃO / PREVIEW\n",
        "# ============================================\n",
        "\n",
        "def validar_flat(linhas: List[Dict[str, Any]]) -> None:\n",
        "    if not linhas:\n",
        "        print(\"[Validacao] Flatten sem linhas.\")\n",
        "        return\n",
        "    df = pd.DataFrame(linhas)\n",
        "    df_preview = aplicar_ordem_colunas(df, COL_ORDER)\n",
        "    print(\"\\n[Validacao] Preview (5 linhas):\")\n",
        "    print(df_preview.head(5).to_string(index=False))\n",
        "    print(f\"\\n[Validacao] Total de linhas (testes): {len(df)}\")\n",
        "    if \"sampleId\" in df.columns:\n",
        "        print(f\"[Validacao] Amostras distintas: {df['sampleId'].nunique()}\")\n",
        "    if \"testName\" in df.columns:\n",
        "        exemplos = sorted(df[\"testName\"].dropna().unique())[:10]\n",
        "        print(f\"[Validacao] Exemplos de testes: {exemplos}\")\n",
        "\n",
        "# ============================================\n",
        "# PROCESSAR CSV EXISTENTE (coluna 'results')\n",
        "# ============================================\n",
        "\n",
        "def parse_python_like_json(text: str) -> Any:\n",
        "    \"\"\"\n",
        "    A coluna 'results' costuma vir como string Python-like (aspas simples, None/True/False).\n",
        "    Preferimos literal_eval; fallback para JSON.\n",
        "    \"\"\"\n",
        "    txt = str(text).strip()\n",
        "    # Remove aspas externas se houver\n",
        "    if (txt.startswith('\"') and txt.endswith('\"')) or (txt.startswith(\"'\") and txt.endswith(\"'\")):\n",
        "        txt = txt[1:-1]\n",
        "    # Primeiro tenta literal_eval (aceita aspas simples e None/True/False)\n",
        "    try:\n",
        "        return ast.literal_eval(txt)\n",
        "    except Exception:\n",
        "        # Fallback: tokens Python -> JSON\n",
        "        txt2 = txt.replace(\"None\", \"null\").replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
        "        return json.loads(txt2)\n",
        "\n",
        "def processar_csv_results_file(src_file: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Lê CSV de entrada detectando automaticamente o delimitador (',' ou ';')\n",
        "    e extrai a coluna 'results' com o array serializado.\n",
        "    \"\"\"\n",
        "    sep_in = detectar_sep_csv(src_file)\n",
        "    print(f\"[CSV] Lendo: {src_file} | delimitador detectado: '{sep_in}'\")\n",
        "    df_raw = pd.read_csv(src_file, sep=sep_in, encoding=CSV_ENCODING, engine=\"c\", dtype=str)\n",
        "    if \"results\" not in df_raw.columns:\n",
        "        # Tenta localizar coluna que contenha o array (fallback)\n",
        "        possiveis = [c for c in df_raw.columns if \"results\" in c.lower()]\n",
        "        if possiveis:\n",
        "            df_raw.rename(columns={possiveis[0]: \"results\"}, inplace=True)\n",
        "        else:\n",
        "            raise RuntimeError(\"CSV não possui coluna 'results'.\")\n",
        "\n",
        "    all_items: List[Dict[str, Any]] = []\n",
        "    for s in df_raw[\"results\"].dropna().astype(str).tolist():\n",
        "        payload = parse_python_like_json(s)\n",
        "        if isinstance(payload, list):\n",
        "            all_items.extend(payload)\n",
        "        elif isinstance(payload, dict) and \"items\" in payload:\n",
        "            all_items.extend(payload[\"items\"])\n",
        "        else:\n",
        "            # se for um único objeto, adiciona\n",
        "            if isinstance(payload, dict):\n",
        "                all_items.append(payload)\n",
        "    print(f\"[CSV] Items extraídos de 'results': {len(all_items)}\")\n",
        "    return all_items\n",
        "\n",
        "# ============================================\n",
        "# EXECUÇÃO PRINCIPAL (API)\n",
        "# ============================================\n",
        "\n",
        "def executar_via_api():\n",
        "    print(\"Iniciando via API:\", datetime.now())\n",
        "    session = requests.Session()\n",
        "    token = autenticar(session=session)\n",
        "\n",
        "    # Equipamentos (ativos)\n",
        "    equipamentos = coletar_equipamentos(token, session=session)\n",
        "    if equipamentos:\n",
        "        salvar_csv_table(pd.DataFrame(equipamentos), f\"equipamentos_{datetime.now().date()}.csv\")\n",
        "    else:\n",
        "        print(\"[Equipamentos] Nenhum dado retornado.\")\n",
        "\n",
        "    # Resultados em janelas + paginação\n",
        "    resultados = coletar_resultados(token, periodo_dias=PERIODO_DIAS, chunk_dias=CHUNK_DIAS, session=session)\n",
        "    if resultados:\n",
        "        # Flatten → CSV\n",
        "        linhas_flat = flatten_resultados(resultados)\n",
        "        validar_flat(linhas_flat)\n",
        "        df_flat = pd.DataFrame(linhas_flat)\n",
        "        salvar_csv_table(df_flat, f\"resultados_flat_{datetime.now().date()}.csv\")\n",
        "    else:\n",
        "        print(\"[Resultados] Nenhum dado retornado.\")\n",
        "\n",
        "    print(\"Finalizado:\", datetime.now())\n",
        "\n",
        "# ============================================\n",
        "# EXECUÇÃO PRINCIPAL (CSV existente com 'results')\n",
        "# ============================================\n",
        "\n",
        "def executar_via_csv(src_file: str):\n",
        "    print(\"Iniciando via CSV:\", datetime.now())\n",
        "    resultados = processar_csv_results_file(src_file)\n",
        "    if not resultados:\n",
        "        print(\"[CSV] Nenhum item encontrado em 'results'.\")\n",
        "        return\n",
        "\n",
        "    # Flatten → CSV\n",
        "    linhas_flat = flatten_resultados(resultados)\n",
        "    validar_flat(linhas_flat)\n",
        "    df_flat = pd.DataFrame(linhas_flat)\n",
        "    salvar_csv_table(df_flat, f\"resultados_flat_{datetime.now().date()}.csv\")\n",
        "\n",
        "    print(\"Finalizado:\", datetime.now())\n",
        "\n",
        "# ============================================\n",
        "# MAIN\n",
        "# ============================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ensure_dir(PASTA_SAIDA)\n",
        "    try:\n",
        "        if MODE == \"csv\":\n",
        "            if not SRC_FILE:\n",
        "                raise RuntimeError(\"Defina SRC_FILE=/caminho/arquivo.csv quando MODE=csv.\")\n",
        "            executar_via_csv(SRC_FILE)\n",
        "        else:\n",
        "            executar_via_api()\n",
        "    except Exception as e:\n",
        "        print(\"Falha na execução:\", e)\n"
      ],
      "metadata": {
        "id": "BoKwN1b0ot3v",
        "outputId": "ff18bac7-b8d1-4e49-9ad2-f7797d8c881e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando via API: 2026-01-13 23:13:52.745979\n",
            "[LOGIN] Status: 400 Bad Request | Content-Type: \n",
            "[LOGIN] Body (até 1000 chars): \n",
            "[LOGIN] Headers: {'Date': 'Tue, 13 Jan 2026 23:13:52 GMT'}\n",
            "[LOGIN] Autenticado com payload: ['username', 'password']\n",
            "[API] GET equipamento/list tentativa 1/3 Status: 405 Method Not Allowed | Content-Type: application/xml;charset=UTF-8\n",
            "[API] GET equipamento/list tentativa 1/3 Body (até 1000 chars): <Map><timestamp>1768346033091</timestamp><status>405</status><error>Method Not Allowed</error><path>/api/v1/equipamento/list</path></Map>\n",
            "[API] GET equipamento/list tentativa 1/3 Headers: {'Date': 'Tue, 13 Jan 2026 23:13:52 GMT'}\n",
            "[Equipamentos] Nenhum dado retornado.\n",
            "[Resultados] Janelas geradas: 12 (de 2025-01-13 até 2026-01-13)\n",
            "[Resultados] Janela 2025-01-13 → 2025-02-12\n",
            "[Resultados] 2025-01-13 → 2025-02-12 | pág 1 | itens 1 | acumulado 1\n",
            "[Resultados] Janela 2025-02-13 → 2025-03-15\n",
            "[Resultados] 2025-02-13 → 2025-03-15 | pág 1 | itens 1 | acumulado 2\n",
            "[Resultados] Janela 2025-03-16 → 2025-04-15\n",
            "[Resultados] 2025-03-16 → 2025-04-15 | pág 1 | itens 1 | acumulado 3\n",
            "[Resultados] Janela 2025-04-16 → 2025-05-16\n",
            "[Resultados] 2025-04-16 → 2025-05-16 | pág 1 | itens 1 | acumulado 4\n",
            "[Resultados] Janela 2025-05-17 → 2025-06-16\n",
            "[Resultados] 2025-05-17 → 2025-06-16 | pág 1 | itens 1 | acumulado 5\n",
            "[Resultados] Janela 2025-06-17 → 2025-07-17\n",
            "[Resultados] 2025-06-17 → 2025-07-17 | pág 1 | itens 1 | acumulado 6\n",
            "[Resultados] Janela 2025-07-18 → 2025-08-17\n",
            "[Resultados] 2025-07-18 → 2025-08-17 | pág 1 | itens 1 | acumulado 7\n",
            "[Resultados] Janela 2025-08-18 → 2025-09-17\n",
            "[Resultados] 2025-08-18 → 2025-09-17 | pág 1 | itens 1 | acumulado 8\n",
            "[Resultados] Janela 2025-09-18 → 2025-10-18\n",
            "[Resultados] 2025-09-18 → 2025-10-18 | pág 1 | itens 1 | acumulado 9\n",
            "[Resultados] Janela 2025-10-19 → 2025-11-18\n",
            "[Resultados] 2025-10-19 → 2025-11-18 | pág 1 | itens 1 | acumulado 10\n",
            "[Resultados] Janela 2025-11-19 → 2025-12-19\n"
          ]
        }
      ]
    }
  ]
}